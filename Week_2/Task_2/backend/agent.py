import asyncio
from typing import AsyncIterator

from langchain.agents import AgentType, initialize_agent
from langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI

from tools import tools


class StreamingAgent:
    def __init__(self, model_name: str, api_key: str, memory_k: int = 5):
        self.callback = AsyncIteratorCallbackHandler()
        self.llm = ChatOpenAI(
            model=model_name, api_key=api_key, streaming=True, callbacks=[self.callback]
        )
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="output",
        )
        self.agent = initialize_agent(
            tools=tools,
            llm=self.llm,
            memory=self.memory,
            agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
            verbose=False,
            handle_parsing_errors=True,
        )

    async def run_stream(self, user_input: str) -> AsyncIterator[str]:
        """
        Asynchronously yields response chunks as they are generated by the agent.

        Args:
            user_input (str): Input text from the user.

        Yields:
            str: Chunk of the agent's response.
        """
        full_response = ""
        capture = False

        try:
            async for event in self.agent.with_config().astream_events(
                {"input": user_input}, version="v1"
            ):
                # print(event) # Show event for check correct work
                if event["event"] == "on_chat_model_stream":
                    content = event["data"]["chunk"].content
                    print(f"Chunk from agent: {repr(content)}")  #
                    full_response += content
                    if capture:
                        yield content
                    elif "AI:" in full_response:
                        capture = True
        except asyncio.CancelledError:
            print("\n\nrun_stream cancelled\n\n")
            return
