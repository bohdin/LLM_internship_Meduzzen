import json

from openai import OpenAI
from rich.console import Console
from rich.live import Live
from rich.text import Text

from chat_session import ChatSession
from tools import call_function


def stream_assistant_response(
    client: OpenAI,
    model_name: str,
    messages: list[dict],
    tools: list[dict],
    console: Console,
) -> tuple[str, dict]:
    """
    Streams assistant response token by token and displays it live in the console.

    Args:
        client: OpenAI client.
        model_name (str): The model to use.
        messages (list): Chat messages.
        tools (list): Available function tools for the model.
        console: Rich console instance for output.

    Returns:
        tuple: Full assistant reply (str) and any tool calls (dict).
    """

    stream = client.chat.completions.create(
        model=model_name, messages=messages, tools=tools, stream=True
    )

    assistant_reply = ""
    final_tool_calls = {}

    with Live(
        Text("Assistant is typing...", style="dim"),
        refresh_per_second=10,
        console=console,
        transient=True,
    ) as live:
        for chunk in stream:
            delta = chunk.choices[0].delta

            if delta.tool_calls:
                for tool_call in delta.tool_calls:
                    index = tool_call.index
                    if index not in final_tool_calls:
                        final_tool_calls[index] = tool_call
                    final_tool_calls[
                        index
                    ].function.arguments += tool_call.function.arguments

            if delta.content:
                assistant_reply += delta.content
                live.update(
                    Text.assemble(("Assistant: ", "dim"), (assistant_reply, "default"))
                )
    if assistant_reply:
        console.print(
            Text.assemble(("Assistant: ", "dim"), (assistant_reply, "default"))
        )

    return assistant_reply, final_tool_calls


def handle_tool_call(tool_call: dict, session: ChatSession) -> None:
    """
    Handles a tool function call by executing it and storing the result in the chat session.

    Args:
        tool_call (dict): The function call data generated by the assistant.
        session (ChatSession): The current chat session to which messages are appended.
    """
    name = tool_call.function.name
    args = json.loads(tool_call.function.arguments)
    result = call_function(name, args)
    session.add_message(
        role="assistant",
        content=None,
        tool_calls=[
            {
                "id": tool_call.id,
                "type": "function",
                "function": {"name": name, "arguments": tool_call.function.arguments},
            }
        ],
    )
    session.add_message("tool", str(result), tool_call.id)
