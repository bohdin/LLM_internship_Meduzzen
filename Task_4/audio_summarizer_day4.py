from openai import OpenAI
from dotenv import load_dotenv
import os
import argparse
import json
from datetime import datetime

load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")

if not API_KEY:
    raise ValueError("OPENAI_API_KEY not found in .env file!")

client = OpenAI(api_key=API_KEY)
parser = argparse.ArgumentParser()
parser.add_argument("--mode", type=str)
args = parser.parse_args()

def main():

    model_name = 'gpt-4o'

    dict_gpt_task = {
        "summary": "Write a short summary (1-2 sentences) of the following transcript",
        "extract_keywords": "Extract relevant five keywords or key phrases from the following transcript. Separate them with commas",
        "generate_title": "Generate a concise and informative title that contains the main idea of the following transcript"
    }

    mode = args.mode

    if mode is None:
        mode = "summary"

    if mode not in dict_gpt_task.keys() and mode != "custom":
        raise ValueError(f"Not correct --mode task: {mode}")
    
    if mode != "custom":
        instructions = dict_gpt_task[mode]


    while True:

        user_input = input("You uploaded: ")


        if user_input.lower() in ["quit", "exit"]:
                    print("Goodbye!")
                    break  
        

        audio_paths = [audio_path.strip() for audio_path in user_input.split(";")]

        
        for audio_path in audio_paths:

            if not audio_path:
                continue

            if not os.path.exists(audio_path):
                        print(f"\nFile doesn't exist {audio_path}")
                        continue
            
            print(f"\nFile: {audio_path}")
            with open(audio_path, "rb") as audio_file:
                transcription = client.audio.transcriptions.create(
                    file=audio_file,
                    model="whisper-1",
                    response_format="verbose_json"
                )

            transcription_input = ""
            for segment in transcription.segments:
                start = segment.start
                end = segment.end
                text = segment.text
                transcription_input += f"[{start:.2f}s - {end:.2f}s]: {text}\n"

            print(f"-> Transcript: {transcription_input}")

            if mode == "custom":
                while True:
                    new_prompt = input("Enter prompt for GPT (write 'default' for return default prompt): ")
                                
                    instructions = dict_gpt_task[mode] if new_prompt == "default" else new_prompt

                    response = client.responses.create(
                        model=model_name,
                        instructions=instructions,
                        input=transcription_input
                    )

                    print(f"\n-> GPT Summary: {response.output_text}", end="\n\n")

                    transcripts_and_summaries_log(mode, instructions, transcription_input, response.output_text)

                    again = input("\nTry another summarization prompts? (yes/not): ")

                    if again != "yes":
                        break
            else:
                response = client.responses.create(
                        model=model_name,
                        instructions=instructions,
                        input=transcription_input
                    )
                 
                print(f"\n-> GPT Summary: {response.output_text}", end="\n\n")

                transcripts_and_summaries_log(mode, instructions, transcription_input, response.output_text)
                 

def transcripts_and_summaries_log(mode: str, prompt: str, transcript: str, summary: str) -> None:
    """
    Save transcript, GPT prompt, and summary result to a JSON log file

    Args:
        mode (str): The selected processing mode ("summary", "extract_keywords", "generate_title", "custom")
        prompt (str): The GPT prompt used to generate the output
        transcript (str): The full transcribed text of the audio file
        summary (str): The response generated by the GPT model based on the transcript and prompt
    """
    os.makedirs("logs", exist_ok=True)

    log_data = {
        "mode": mode,
        "prompt": prompt,
        "transcript": transcript,
        "summary": summary
    }

    current_date = datetime.now().strftime("%Y-%m-%d")
    file_name = f"logs\{current_date}.json"

    if os.path.exists(file_name):
        with open(file_name, "r", encoding="utf-8") as f:
            try:
                data = json.load(f)
                if not isinstance(data, list):
                    data = [data]
            except json.JSONDecodeError:
                data = []
                
    else:
        data = []

    data.append(log_data)
    
    with open(file_name, "w", encoding="utf-8") as f:
         json.dump(data, f, indent=2)

if __name__ == "__main__":
    main()